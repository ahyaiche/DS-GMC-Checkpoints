{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint Objective\n",
    "In this exercise, you will learn how to create your own chatbot by modifying the code provided in the example in our course. You will need to choose a topic that you want your chatbot to be based on and find a text file related to that topic. Then, you will need to modify the code to preprocess the data in the text file and create a chatbot interface that can interact with the user.\n",
    "\n",
    "Note:\n",
    "\n",
    "To run your code, you need to have the text file in the same directory as your Python script.\n",
    "\n",
    "You may want to test your chatbot with different types of questions to ensure that it is working correctly.\n",
    "\n",
    "You can continue to modify your chatbot to add additional features or improve its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\acer\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import requests\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Choose a topic: Choose a topic that you are interested in and find a text file related to that topic. You can use websites such as Project Gutenberg to find free text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the text file from the URL\n",
    "url = \"https://www.gutenberg.org/cache/epub/42671/pg42671.txt\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Open and save the file \n",
    "with open(\"pg42671.txt\", \"wb\") as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "# Load the text file and preprocess the data\n",
    "with open('pg42671.txt', 'r', encoding='utf-8') as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Preprocess the data: Modify the preprocess() function in the code provided to preprocess the data in your text file. You may want to modify the stop words list or add additional preprocessing steps to better suit your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text into sentences\n",
    "sentences = sent_tokenize(data)\n",
    "\n",
    "# Define a function to preprocess each sentence\n",
    "def preprocess(sentence):\n",
    "\n",
    "    # Tokenize the sentence into words\n",
    "    words = word_tokenize(sentence)\n",
    "\n",
    "    # Remove stopwords and punctuation\n",
    "    words = [word.lower() for word in words if word.lower() not in stopwords.words('english') and word not in string.punctuation]\n",
    "    \n",
    "    # Lemmatize the words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return words\n",
    "\n",
    "# Preprocess each sentence in the text\n",
    "corpus = [preprocess(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Define the similarity function: Modify the get_most_relevant_sentence() function to compute the similarity between the user's query and each sentence in your text file. You may want to modify the similarity metric or add additional features to improve the performance of your chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to find the most relevant sentence given a query\n",
    "def get_most_relevant_sentence(query, sentences):\n",
    "    vectorizer = CountVectorizer().fit_transform(sentences + [query])\n",
    "    vectors = vectorizer.toarray()\n",
    "    similarity_scores = cosine_similarity(vectors)\n",
    "    most_similar_index = similarity_scores.shape[0] - 1\n",
    "    most_relevant_index = similarity_scores[most_similar_index].argsort()[-2]\n",
    "    return sentences[most_relevant_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Define the chatbot function: Modify the chatbot() function to return an appropriate response based on the most relevant sentence in your text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The chabot function\n",
    "def chatbot(question):\n",
    "    # Find the most relevant sentence\n",
    "    most_relevant_sentence = get_most_relevant_sentence(query, corpus)\n",
    "    # Return the answer\n",
    "    return most_relevant_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Create a Streamlit app: Use the main() function in the code provided as a template to create a web-based chatbot interface. Prompt the user for a question, call the chatbot() function to get the response, and display it on the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-31 02:57:52.880 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\acer\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "# Create a Streamlit app\n",
    "def main():\n",
    "    st.title(\"Chatbot\")\n",
    "    st.write(\"Hello! I'm a chatbot. Ask me anything about the topic in the text file.\")\n",
    "    # Get the user's question\n",
    "    question = st.text_input(\"Question:\")\n",
    "    # Create a button to submit the question\n",
    "    if st.button(\"Submit\"):\n",
    "        # Call the chatbot function with the question and display the response\n",
    "        response = chatbot(question)\n",
    "        st.write(\"Chatbot response: \" + response)\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mani",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
